{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Query on Cloud Stored Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While data is necessary for all ML projects, the vast amount of datasets used can become too much for a local machine to store. For example, the 2 GB CSV file used in this example, read in locally has a noticable latency taking several seconds. An API would be an obvious solution as it solves many of the problems using a CSV presents. But for the sake of this example, as an individual long investor, I need an efficent way to store decades of price action that won't hinder my machine's preformance. \n",
    "\n",
    "Using data from [Kaggle](https://www.kaggle.com/tsaustin/us-historical-stock-prices-with-earnings-data), I've uploaded the csv to an AWS S3 Bucket in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myles/anaconda3/lib/python3.7/site-packages/google/colab/data_table.py:30: UserWarning:\n",
      "\n",
      "IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import cufflinks as cf\n",
    "import plotly.offline as plyo\n",
    "plyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',region_name='us-east-1',aws_access_key_id=AccessKey, aws_secret_access_key = SecretKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"SELECT * FROM S3Object s WHERE s._1 = 'AMZN';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.select_object_content(Bucket='mylesnewbucket1',\n",
    "                                   Key = 'stock_prices_latest.csv',\n",
    "                                   ExpressionType='SQL',\n",
    "                                   Expression = exp,\n",
    "                                   InputSerialization = {'CSV': {'FileHeaderInfo':'IGNORE'}},\n",
    "                                   OutputSerialization = {'CSV': {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5547\n",
      "  symbol        date    open     high       low   close  close_adjusted  \\\n",
      "0   AMZN  2016-04-11  596.14  604.000  594.9100  595.93          595.93   \n",
      "1   AMZN  2009-03-31   72.61   74.500   72.1200   73.44           73.44   \n",
      "2   AMZN  2011-05-18  194.13  198.283  193.2500  197.09          197.09   \n",
      "3   AMZN  2015-11-05  647.10  657.000  643.0901  655.65          655.65   \n",
      "4   AMZN  2009-07-28   83.84   85.640   82.6000   84.98           84.98   \n",
      "\n",
      "    volume  split_coef  \n",
      "0  2704267         1.0  \n",
      "1  8918200         1.0  \n",
      "2  4955800         1.0  \n",
      "3  4723825         1.0  \n",
      "4  8774900         1.0  \n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for event in response['Payload']:\n",
    "    if 'Records' in event:\n",
    "        records.append(event['Records']['Payload'])\n",
    "file_str = ''.join(r.decode('utf-8') for r in records)\n",
    "\n",
    "select_df = pd.read_csv(StringIO(file_str), \n",
    "                   names=['symbol','date','open','high','low','close','close_adjusted','volume','split_coef'])\n",
    "print(len(select_df))\n",
    "print(select_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_adjusted</th>\n",
       "      <th>volume</th>\n",
       "      <th>split_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>596.14</td>\n",
       "      <td>604.000</td>\n",
       "      <td>594.9100</td>\n",
       "      <td>595.93</td>\n",
       "      <td>595.93</td>\n",
       "      <td>2704267</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>72.61</td>\n",
       "      <td>74.500</td>\n",
       "      <td>72.1200</td>\n",
       "      <td>73.44</td>\n",
       "      <td>73.44</td>\n",
       "      <td>8918200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2011-05-18</td>\n",
       "      <td>194.13</td>\n",
       "      <td>198.283</td>\n",
       "      <td>193.2500</td>\n",
       "      <td>197.09</td>\n",
       "      <td>197.09</td>\n",
       "      <td>4955800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-11-05</td>\n",
       "      <td>647.10</td>\n",
       "      <td>657.000</td>\n",
       "      <td>643.0901</td>\n",
       "      <td>655.65</td>\n",
       "      <td>655.65</td>\n",
       "      <td>4723825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2009-07-28</td>\n",
       "      <td>83.84</td>\n",
       "      <td>85.640</td>\n",
       "      <td>82.6000</td>\n",
       "      <td>84.98</td>\n",
       "      <td>84.98</td>\n",
       "      <td>8774900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>1885.88</td>\n",
       "      <td>1887.110</td>\n",
       "      <td>1858.5500</td>\n",
       "      <td>1869.44</td>\n",
       "      <td>1869.44</td>\n",
       "      <td>3446381</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1885.89</td>\n",
       "      <td>1886.640</td>\n",
       "      <td>1857.2500</td>\n",
       "      <td>1864.72</td>\n",
       "      <td>1864.72</td>\n",
       "      <td>3948459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>1891.31</td>\n",
       "      <td>1898.000</td>\n",
       "      <td>1880.8000</td>\n",
       "      <td>1891.30</td>\n",
       "      <td>1891.30</td>\n",
       "      <td>2753903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1872.25</td>\n",
       "      <td>1878.860</td>\n",
       "      <td>1855.0900</td>\n",
       "      <td>1862.02</td>\n",
       "      <td>1862.02</td>\n",
       "      <td>2896592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>1905.37</td>\n",
       "      <td>1906.940</td>\n",
       "      <td>1880.0000</td>\n",
       "      <td>1883.16</td>\n",
       "      <td>1883.16</td>\n",
       "      <td>2856959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5547 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol        date     open      high        low    close  \\\n",
       "0      AMZN  2016-04-11   596.14   604.000   594.9100   595.93   \n",
       "1      AMZN  2009-03-31    72.61    74.500    72.1200    73.44   \n",
       "2      AMZN  2011-05-18   194.13   198.283   193.2500   197.09   \n",
       "3      AMZN  2015-11-05   647.10   657.000   643.0901   655.65   \n",
       "4      AMZN  2009-07-28    83.84    85.640    82.6000    84.98   \n",
       "...     ...         ...      ...       ...        ...      ...   \n",
       "5542   AMZN  2020-01-14  1885.88  1887.110  1858.5500  1869.44   \n",
       "5543   AMZN  2020-01-17  1885.89  1886.640  1857.2500  1864.72   \n",
       "5544   AMZN  2020-01-13  1891.31  1898.000  1880.8000  1891.30   \n",
       "5545   AMZN  2020-01-15  1872.25  1878.860  1855.0900  1862.02   \n",
       "5546   AMZN  2020-01-10  1905.37  1906.940  1880.0000  1883.16   \n",
       "\n",
       "      close_adjusted   volume  split_coef  \n",
       "0             595.93  2704267         1.0  \n",
       "1              73.44  8918200         1.0  \n",
       "2             197.09  4955800         1.0  \n",
       "3             655.65  4723825         1.0  \n",
       "4              84.98  8774900         1.0  \n",
       "...              ...      ...         ...  \n",
       "5542         1869.44  3446381         1.0  \n",
       "5543         1864.72  3948459         1.0  \n",
       "5544         1891.30  2753903         1.0  \n",
       "5545         1862.02  2896592         1.0  \n",
       "5546         1883.16  2856959         1.0  \n",
       "\n",
       "[5547 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5547 entries, 0 to 5546\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   symbol          5547 non-null   object \n",
      " 1   date            5547 non-null   object \n",
      " 2   open            5547 non-null   float64\n",
      " 3   high            5547 non-null   float64\n",
      " 4   low             5547 non-null   float64\n",
      " 5   close           5547 non-null   float64\n",
      " 6   close_adjusted  5547 non-null   float64\n",
      " 7   volume          5547 non-null   int64  \n",
      " 8   split_coef      5547 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 390.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've brought the memory usage down from 2 GB to 390 KB. One unfortunate aspect to this is that S3 does not support joins yet. So for example, this data also included two additional datasets for Dividends and Returns, if we wanted to incorporate those, we'd have to run another query and use Pandas' join method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
